{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba8e2f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MALIGNANTMASSES': 0, 'CALC': 1, 'BENIGNMASSES': 2, 'NORM': 3}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, ConfusionMatrixDisplay\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cv2 import Canny\n",
    "from skimage.morphology import dilation, erosion, white_tophat, skeletonize\n",
    "from skimage.morphology import disk \n",
    "from skimage import transform\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class_names = ['MALIGNANTMASSES', 'CALC', 'BENIGNMASSES', 'NORM']\n",
    "class_names_label = {class_names:i for i, class_names in enumerate(class_names)}\n",
    "print(class_names_label)\n",
    "\n",
    "IMAGE_SIZE = (224, 224, 3)\n",
    "\n",
    "def load_data():\n",
    "    main_directory = r\"C:\\Users\\hp\\Documents\\CursoML\\processed\\todas\"\n",
    "    \n",
    "    output = []\n",
    "    images = []\n",
    "    labels = []\n",
    "         \n",
    "    for folder in os.listdir(main_directory):\n",
    "        print(folder)\n",
    "        label = list(class_names_label.values())[int(folder)-1]\n",
    "\n",
    "        for file in os.listdir(os.path.join(main_directory, folder)):\n",
    "            img_path = os.path.join(os.path.join(main_directory, folder), file)\n",
    "\n",
    "            image = io.imread(img_path, as_gray=True, plugin='matplotlib')\n",
    "            image = transform.resize(image, IMAGE_SIZE)\n",
    "\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images, dtype='float32')\n",
    "    labels = np.array(labels, dtype='int32')\n",
    "\n",
    "    output.append(images)\n",
    "    output.append(labels)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dab91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "total_images, total_labels = load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16c2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de aprendizaje:  (683, 224, 224, 3) (683,)\n",
      "Datos de prueba:  (456, 224, 224, 3) (456,)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(total_images, total_labels, test_size=0.4)\n",
    "print('Datos de aprendizaje: ', train_X.shape, train_Y.shape)\n",
    "print('Datos de prueba: ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdad88e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 128)     9728      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 224, 224, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 108, 108, 128)     409728    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 108, 108, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 54, 54, 128)       409728    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 54, 54, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 27, 27, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 93312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11944064  \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,773,764\n",
      "Trainable params: 12,773,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import batch_normalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "#CREAR EL MODELO\n",
    "\n",
    "cancer_model = tf.keras.models.Sequential() #pila de capas\n",
    "\n",
    "cancer_model.add(tf.keras.layers.Conv2D(128, kernel_size=(5,5), activation='linear', padding='same', input_shape=(224,224,3))) #capa de convolucion\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.MaxPooling2D((2, 2),padding='same')) #agrupacion\n",
    "cancer_model.add(tf.keras.layers.Conv2D(128, kernel_size=(5,5), activation = 'relu'))\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "cancer_model.add(tf.keras.layers.Conv2D(128, (5, 5), activation='linear', padding='same'))\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "cancer_model.add(tf.keras.layers.Flatten())\n",
    "cancer_model.add(tf.keras.layers.Dense(128, activation='linear'))\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.Dense(4, activation='softmax')) #capa softmax para clasificacion\n",
    "\n",
    "cancer_model.summary()\n",
    "\n",
    "cancer_model.compile(optimizer=\"adam\",\n",
    "                     loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "batch_size = 64 #numero de muestras por actualizacion \n",
    "cancer_train = cancer_model.fit(train_X, train_Y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041c0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
