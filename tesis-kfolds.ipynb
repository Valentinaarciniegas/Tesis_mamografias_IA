{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf68227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from tensorflow import keras\n",
    "import sklearn\n",
    "from tensorflow.python.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from cv2 import Canny\n",
    "from skimage.morphology import dilation, erosion, white_tophat, skeletonize\n",
    "from skimage.morphology import disk \n",
    "from skimage import transform\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837c3dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MALIGNANTMASSES': 0, 'CALC': 1, 'BENIGNMASSES': 2, 'NORM': 3}\n"
     ]
    }
   ],
   "source": [
    "class_names = ['MALIGNANTMASSES', 'CALC', 'BENIGNMASSES', 'NORM']\n",
    "class_names_label = {class_names:i for i, class_names in enumerate(class_names)}\n",
    "print(class_names_label)\n",
    "\n",
    "IMAGE_SIZE = (224, 224, 3)\n",
    "\n",
    "def load_data():\n",
    "    main_directory = r\"C:\\Users\\hp\\Documents\\CursoML\\processed\"\n",
    "    CATEGORY = [\"Training\", \"Testing\"]\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    for category in CATEGORY: \n",
    "        path = os.path.join(main_directory, category)\n",
    "        print(path)\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "       # print(\"Loading {}\".format(category))\n",
    "        \n",
    "        for folder in os.listdir(path):\n",
    "            print(folder)\n",
    "            label = list(class_names_label.values())[int(folder)-1]\n",
    "            \n",
    "            for file in os.listdir(os.path.join(path, folder)):\n",
    "                img_path = os.path.join(os.path.join(path, folder), file)\n",
    "                \n",
    "                image = io.imread(img_path, as_gray=True, plugin='matplotlib')\n",
    "                image = transform.resize(image, IMAGE_SIZE)\n",
    "                \n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype='float32')\n",
    "        labels = np.array(labels, dtype='int32')\n",
    "        \n",
    "        output.append((images, labels))\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c2ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Documents\\CursoML\\processed\\Training\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "C:\\Users\\hp\\Documents\\CursoML\\processed\\Testing\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e6528",
   "metadata": {},
   "source": [
    "## Modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca36b1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 128)     9728      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 224, 224, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 128)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 108, 108, 128)     409728    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 108, 108, 128)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 54, 54, 128)       409728    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 54, 54, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 27, 27, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 93312)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11944064  \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,773,764\n",
      "Trainable params: 12,773,764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from keras.utils import to_categorical\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import batch_normalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "#CREAR EL MODELO\n",
    "\n",
    "cancer_model = tf.keras.models.Sequential() #pila de capas\n",
    "\n",
    "cancer_model.add(tf.keras.layers.Conv2D(128, kernel_size=(5,5), activation='linear', padding='same', input_shape=(224,224,3))) #capa de convolucion\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.MaxPooling2D((2, 2),padding='same')) #agrupacion\n",
    "cancer_model.add(tf.keras.layers.Conv2D(128, kernel_size=(5,5), activation = 'relu'))\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "cancer_model.add(tf.keras.layers.Conv2D(128, (5, 5), activation='linear', padding='same'))\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "cancer_model.add(tf.keras.layers.Flatten())\n",
    "cancer_model.add(tf.keras.layers.Dense(128, activation='linear'))\n",
    "cancer_model.add(LeakyReLU(alpha=0.1))\n",
    "cancer_model.add(tf.keras.layers.Dense(4, activation='softmax')) #capa softmax para clasificacion\n",
    "\n",
    "cancer_model.summary()\n",
    "\n",
    "cancer_model.compile(optimizer=\"adam\",\n",
    "                     loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                     metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a321b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "7/7 [==============================] - 317s 43s/step - loss: 2.4090 - accuracy: 0.4486\n",
      "Epoch 2/12\n",
      "7/7 [==============================] - 296s 41s/step - loss: 1.1200 - accuracy: 0.5828\n",
      "Epoch 3/12\n",
      "7/7 [==============================] - 292s 41s/step - loss: 0.9313 - accuracy: 0.7170\n",
      "Epoch 4/12\n",
      "7/7 [==============================] - 316s 45s/step - loss: 0.7762 - accuracy: 0.7678\n",
      "Epoch 5/12\n",
      "7/7 [==============================] - 304s 42s/step - loss: 0.7065 - accuracy: 0.7545\n",
      "Epoch 6/12\n",
      "7/7 [==============================] - 302s 42s/step - loss: 0.6872 - accuracy: 0.7860\n",
      "Epoch 7/12\n",
      "7/7 [==============================] - 293s 41s/step - loss: 0.6155 - accuracy: 0.8017\n",
      "Epoch 8/12\n",
      "7/7 [==============================] - 309s 43s/step - loss: 0.5610 - accuracy: 0.8102\n",
      "Epoch 9/12\n",
      "7/7 [==============================] - 294s 42s/step - loss: 0.5556 - accuracy: 0.7896\n",
      "Epoch 10/12\n",
      "7/7 [==============================] - 319s 45s/step - loss: 0.5073 - accuracy: 0.8307\n",
      "Epoch 11/12\n",
      "7/7 [==============================] - 312s 44s/step - loss: 0.4474 - accuracy: 0.8331\n",
      "Epoch 12/12\n",
      "7/7 [==============================] - 294s 41s/step - loss: 0.4259 - accuracy: 0.8380\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento\n",
    "epochs = 12\n",
    "batch_size = 128 #numero de muestras por actualizacion \n",
    "cancer_train = cancer_model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d5a3981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 722ms/step - loss: 1.7256 - accuracy: 0.5111\n",
      "Test loss: 1.725643277168274\n",
      "Test accuracy: 0.5111111402511597\n",
      "2/2 [==============================] - 3s 749ms/step - loss: 0.7606 - accuracy: 0.8444\n",
      "Test loss: 0.760597288608551\n",
      "Test accuracy: 0.8444444537162781\n",
      "2/2 [==============================] - 3s 738ms/step - loss: 0.3137 - accuracy: 0.8667\n",
      "Test loss: 0.31370460987091064\n",
      "Test accuracy: 0.8666666746139526\n",
      "2/2 [==============================] - 3s 759ms/step - loss: 0.2369 - accuracy: 0.9556\n",
      "Test loss: 0.23692266643047333\n",
      "Test accuracy: 0.9555555582046509\n",
      "2/2 [==============================] - 3s 710ms/step - loss: 0.2447 - accuracy: 0.9545\n",
      "Test loss: 0.24474965035915375\n",
      "Test accuracy: 0.9545454382896423\n",
      "2/2 [==============================] - 4s 1s/step - loss: 0.6759 - accuracy: 0.7955\n",
      "Test loss: 0.6758866906166077\n",
      "Test accuracy: 0.7954545617103577\n",
      "2/2 [==============================] - 4s 951ms/step - loss: 0.7182 - accuracy: 0.7955\n",
      "Test loss: 0.7181834578514099\n",
      "Test accuracy: 0.7954545617103577\n",
      "\n",
      "Accuracy mean: 0.817604626928057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "folds = 7\n",
    "skf = StratifiedKFold(n_splits=folds)\n",
    "skf.get_n_splits(test_images, test_labels)\n",
    "\n",
    "accuracy_accumulate = 0\n",
    "\n",
    "for train_index, test_index in skf.split(test_images, test_labels):\n",
    "    x_test, y_test = test_images[test_index], test_labels[test_index]\n",
    "    test_eval = cancer_model.evaluate(x_test, y_test)\n",
    "    accuracy_accumulate += test_eval[1]\n",
    "    print('Test loss:', test_eval[0])\n",
    "    print('Test accuracy:', test_eval[1])\n",
    "    \n",
    "accuracy_mean = accuracy_accumulate / folds\n",
    "print(\"\\nAccuracy mean:\", accuracy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2d04174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 69s 5s/step - loss: 0.6928 - accuracy: 0.8301\n",
      "Test loss: 0.6927545666694641\n",
      "Test accuracy: 0.8301281929016113\n"
     ]
    }
   ],
   "source": [
    "test_eval = cancer_model.evaluate(test_images, test_labels)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1936d7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        96\n",
      "           1       0.69      0.86      0.77        71\n",
      "           2       1.00      0.75      0.86        83\n",
      "           3       0.64      0.74      0.69        62\n",
      "\n",
      "    accuracy                           0.83       312\n",
      "   macro avg       0.83      0.82      0.82       312\n",
      "weighted avg       0.86      0.83      0.84       312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = cancer_model.predict(test_images)\n",
    "pred_labels = np.argmax(predictions, axis = 1)\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139108c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
